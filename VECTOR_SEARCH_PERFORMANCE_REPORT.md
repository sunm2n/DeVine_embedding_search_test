# DeVine 벡터 검색 성능 테스트 보고서

**작성일**: 2026-02-02
**테스트 환경**: macOS (Apple Silicon), Docker, PostgreSQL 17 + pgvector
**목적**: Spring 서버 기반 벡터 검색 성능 측정 및 최적화 방안 도출

---

## 1. 테스트 환경 및 아키텍처

### 1.1 시스템 구성

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────────────┐
│   FastAPI       │     │   Spring Boot   │     │  PostgreSQL 17          │
│   (Python)      │────▶│   (Java 21)     │────▶│  + pgvector extension   │
│                 │     │                 │     │                         │
│  - 임베딩 생성   │     │  - 벡터 저장     │     │  - 벡터 저장 (1536차원)  │
│  - OpenAI API   │     │  - 벡터 검색     │     │  - IVFFlat 인덱스       │
└─────────────────┘     └─────────────────┘     └─────────────────────────┘
     :8000                   :8080                     :5433
```

### 1.2 테스트 환경 상세

| 항목 | 사양 |
|------|------|
| OS | macOS (Darwin 24.3.0) |
| CPU | Apple Silicon (ARM64) |
| PostgreSQL | 17 (pgvector/pgvector:pg17 Docker 이미지) |
| pgvector | 최신 버전 (Docker 이미지 내장) |
| Java | OpenJDK 21.0.8 |
| Python | 3.13 |
| 임베딩 모델 | OpenAI text-embedding-3-small |
| 벡터 차원 | 1536 |
| 인덱스 타입 | IVFFlat (lists=10) |

---

## 2. 테스트 결과

### 2.1 소규모 테스트 (5개 데이터)

| 측정 항목 | 평균 | 최소 | 최대 |
|----------|------|------|------|
| 임베딩 생성 (OpenAI API) | 350ms | 245ms | 967ms |
| Spring 서버 저장 | 10ms | 6ms | 25ms |
| 벡터 검색 (Spring 전체) | 8ms | 5ms | 11ms |
| 벡터 검색 (pgvector만) | 4ms | 4ms | 8ms |

### 2.2 중규모 테스트 (100개 데이터)

#### 임베딩 생성 및 저장 (개별 처리, 순차 실행)

| 측정 항목 | 평균 | 최소 | 최대 |
|----------|------|------|------|
| **임베딩 생성** (OpenAI API) | 359.4ms | 240.2ms | 904.2ms |
| **Spring 서버 저장** | 10.4ms | 5.3ms | 18.7ms |

#### 벡터 검색 (100개 데이터 저장 후)

| 측정 항목 | 평균 | 최소 | 최대 |
|----------|------|------|------|
| **Spring 전체 응답** | 19.8ms | 7.8ms | 39.8ms |
| **pgvector 검색만** | 15.9ms | 4.0ms | 36.0ms |

### 2.3 Cold Start vs Warm Cache 현상

연속 검색 시 시간 변화 패턴:

```
1번째 쿼리:  39ms  ← Cold Start (캐시 없음, 디스크 I/O)
2번째 쿼리:  25ms  ← 워밍업 중
3번째 쿼리:  23ms  ← 워밍업 중
4번째 쿼리:  22ms  ← 캐시 적용 시작
5번째 쿼리:  20ms  ← 안정화
...
10번째 쿼리: 19ms  ← 안정화 완료
```

**핵심 발견**: 첫 번째 쿼리는 안정화된 쿼리 대비 약 **2배 느림**

---

## 3. PostgreSQL 버퍼 캐시 상세 설명

### 3.1 버퍼 캐시란?

PostgreSQL 버퍼 캐시(Buffer Cache)는 **디스크의 데이터를 메모리에 임시 저장**하는 영역입니다. 이를 통해 동일한 데이터에 대한 반복 접근 시 디스크 I/O를 피하고 메모리에서 직접 읽어 성능을 대폭 향상시킵니다.

```
┌─────────────────────────────────────────────────────────────────┐
│                        PostgreSQL                                │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                   Shared Buffers                         │    │
│  │              (버퍼 캐시 = 메모리 영역)                     │    │
│  │                                                          │    │
│  │   ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐       │    │
│  │   │ Page 1  │ │ Page 2  │ │ Page 3  │ │ Page N  │       │    │
│  │   │ (8KB)   │ │ (8KB)   │ │ (8KB)   │ │ (8KB)   │       │    │
│  │   └─────────┘ └─────────┘ └─────────┘ └─────────┘       │    │
│  └─────────────────────────────────────────────────────────┘    │
│                              ▲                                   │
│                              │ 캐시 히트 시: ~0.1ms              │
│                              │                                   │
│                              ▼                                   │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                      디스크 (SSD/HDD)                     │    │
│  │                   캐시 미스 시: ~1-10ms                   │    │
│  └─────────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────────┘
```

### 3.2 버퍼 캐시 동작 원리

#### 첫 번째 쿼리 (Cold Start)
```
1. 쿼리 실행 요청
2. 버퍼 캐시 확인 → 데이터 없음 (Cache Miss)
3. 디스크에서 데이터 페이지 로드 (느림: 1-10ms per page)
4. 버퍼 캐시에 저장
5. 결과 반환
   → 총 소요: 36-40ms
```

#### 두 번째 이후 쿼리 (Warm Cache)
```
1. 쿼리 실행 요청
2. 버퍼 캐시 확인 → 데이터 있음 (Cache Hit)
3. 메모리에서 직접 읽기 (빠름: 0.1ms)
4. 결과 반환
   → 총 소요: 4-20ms
```

### 3.3 벡터 검색에서 버퍼 캐시의 역할

pgvector의 벡터 검색은 다음 데이터를 캐싱합니다:

| 캐싱 대상 | 크기 (100개 기준) | 캐싱 효과 |
|----------|------------------|----------|
| 벡터 데이터 | 약 600KB (1536 × 4bytes × 100) | 높음 |
| IVFFlat 인덱스 | 약 100KB | 매우 높음 |
| 메타데이터 | 수 KB | 보통 |

---

## 4. 최적화 방안 및 예상 결과

### 4.1 PostgreSQL 버퍼 캐시 최적화

#### 방법
```sql
-- postgresql.conf 설정
shared_buffers = 256MB          -- 기본 128MB → 256MB 증가
effective_cache_size = 1GB      -- OS 캐시까지 고려한 크기
work_mem = 64MB                 -- 정렬/해시 작업용 메모리
```

#### 예상 결과
| 항목 | 현재 | 최적화 후 예상 |
|------|------|--------------|
| Cold Start | 36-40ms | 25-30ms |
| Warm Cache | 19-20ms | 15-18ms |
| 캐시 히트율 | 60-70% | 85-95% |

### 4.2 인덱스 최적화 (IVFFlat → HNSW)

#### 현재 상태: IVFFlat
```sql
CREATE INDEX ON report_embeddings
USING ivfflat (embedding vector_cosine_ops) WITH (lists = 10);
```

#### 최적화: HNSW 인덱스
```sql
-- HNSW: 더 빠른 검색, 더 높은 정확도 (메모리 사용량 증가)
CREATE INDEX ON report_embeddings
USING hnsw (embedding vector_cosine_ops) WITH (m = 16, ef_construction = 64);
```

#### IVFFlat vs HNSW 비교

| 항목 | IVFFlat | HNSW |
|------|---------|------|
| 검색 속도 | 보통 | **빠름** (2-5배) |
| 인덱스 빌드 시간 | 빠름 | 느림 |
| 메모리 사용량 | 적음 | **많음** (2-3배) |
| 정확도 (Recall) | 보통 (lists 의존) | **높음** |
| 추천 데이터 규모 | 10만 이하 | 10만 이상 |

#### 예상 결과
| 항목 | IVFFlat (현재) | HNSW (변경 후) |
|------|---------------|---------------|
| 검색 시간 (100개) | 15-20ms | **5-10ms** |
| 검색 시간 (10,000개) | 50-100ms | **10-20ms** |
| 메모리 사용량 | 1x | 2-3x |

### 4.3 벡터 차원 축소

#### 방법: text-embedding-3-small의 차원 축소 기능 활용

OpenAI의 text-embedding-3-small은 **Matryoshka Representation Learning**을 지원하여, 생성 시 차원을 지정할 수 있습니다.

```python
# 현재: 1536차원
response = client.embeddings.create(
    model="text-embedding-3-small",
    input=text
)

# 최적화: 512차원으로 축소
response = client.embeddings.create(
    model="text-embedding-3-small",
    input=text,
    dimensions=512  # 1536 → 512로 축소
)
```

#### 차원별 성능 비교 (예상)

| 차원 | 저장 용량 | 검색 속도 | 정확도 손실 |
|------|----------|----------|------------|
| 1536 (현재) | 6KB/벡터 | 1x (기준) | 0% |
| 1024 | 4KB/벡터 | 1.3x 빠름 | 1-2% |
| 768 | 3KB/벡터 | 1.5x 빠름 | 2-3% |
| **512** | **2KB/벡터** | **2x 빠름** | **3-5%** |
| 256 | 1KB/벡터 | 3x 빠름 | 8-10% |

#### 예상 결과 (512차원 적용 시)
| 항목 | 1536차원 (현재) | 512차원 (변경 후) |
|------|----------------|-----------------|
| 벡터 저장 크기 | 6KB | 2KB (-67%) |
| 검색 시간 | 15-20ms | **8-12ms** |
| 검색 정확도 | 100% | 95-97% |

### 4.4 검색 쿼리 최적화

#### 방법 1: 프리페칭 (Pre-fetching)

서버 시작 시 더미 쿼리를 실행하여 캐시 워밍업:

```java
@EventListener(ApplicationReadyEvent.class)
public void warmUpCache() {
    // 서버 시작 시 더미 검색으로 캐시 워밍업
    float[] dummyVector = new float[1536];
    repository.findSimilarByCosineSimilarity(vectorToString(dummyVector), 1);
    log.info("Cache warmed up");
}
```

#### 방법 2: 부분 검색 (Approximate Search)

IVFFlat의 probes 파라미터 조정:

```sql
-- 정확도를 조금 희생하고 속도 향상
SET ivfflat.probes = 1;  -- 기본값: 1, 높을수록 정확하지만 느림
```

#### 방법 3: 배치 검색

여러 벡터를 한 번에 검색:

```sql
-- 개별 검색 대신 배치 검색
SELECT report_id, report_title, embedding <=> $1 as distance
FROM report_embeddings
WHERE embedding <=> $1 < 0.5  -- 유사도 임계값으로 필터링
ORDER BY distance
LIMIT 10;
```

### 4.5 최적화 조합 적용 시 예상 결과

모든 최적화를 적용할 경우:

| 항목 | 현재 (100개) | 최적화 후 예상 (100개) | 최적화 후 예상 (10,000개) |
|------|-------------|---------------------|------------------------|
| Cold Start | 36-40ms | 15-20ms | 30-40ms |
| Warm Cache | 15-20ms | **5-8ms** | **10-15ms** |
| 저장 용량 | 600KB | 200KB | 20MB |

---

## 5. 로컬 환경 vs AWS 클라우드 환경

### 5.1 환경별 예상 성능 차이

```
┌─────────────────────────────────────────────────────────────────────────┐
│                          성능 비교 다이어그램                              │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  로컬 개발 환경 (현재 테스트)                                             │
│  ┌──────────┐    ┌──────────┐    ┌──────────┐                          │
│  │ FastAPI  │◄──►│ Spring   │◄──►│ Postgres │   네트워크: ~1ms         │
│  │ :8000    │    │ :8080    │    │ :5433    │   모두 같은 머신          │
│  └──────────┘    └──────────┘    └──────────┘                          │
│                                                                         │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  AWS 클라우드 환경 (실제 배포)                                            │
│  ┌──────────┐    ┌──────────┐    ┌──────────┐                          │
│  │ Lambda/  │◄──►│ ECS/EC2  │◄──►│ RDS      │   네트워크: 1-5ms        │
│  │ ECS      │    │          │    │ Postgres │   각각 다른 인스턴스       │
│  └──────────┘    └──────────┘    └──────────┘                          │
│       │                                │                                │
│       └────────────── VPC ─────────────┘                                │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### 5.2 AWS 환경에서 추가되는 지연 요소

| 구간 | 로컬 | AWS (동일 AZ) | AWS (다른 AZ) |
|------|------|--------------|--------------|
| 클라이언트 → Spring | ~1ms | 1-3ms | 2-5ms |
| Spring → PostgreSQL | ~1ms | 1-2ms | 2-3ms |
| 전체 네트워크 오버헤드 | ~2ms | **3-5ms** | **5-10ms** |

### 5.3 AWS 환경에서 발생할 수 있는 문제

#### 문제 1: Cold Start 심화 (Lambda/ECS 사용 시)

```
Lambda Cold Start 시나리오:

1. 사용자 요청 도착
2. Lambda 컨테이너 생성 (500ms-2s) ← 추가 지연
3. Java 런타임 초기화 (1-3s) ← 추가 지연
4. Spring 애플리케이션 시작 (2-5s) ← 추가 지연
5. DB 커넥션 풀 생성 (100-500ms) ← 추가 지연
6. 첫 번째 쿼리 실행 (캐시 없음)

   최악의 경우 첫 요청: 5-10초
```

#### 문제 2: RDS 버퍼 캐시 공유

```
┌─────────────────────────────────────────────────────────────┐
│                    RDS PostgreSQL                            │
│                                                              │
│   ┌─────────────────────────────────────────────────────┐   │
│   │              Shared Buffers (공유 영역)               │   │
│   │                                                      │   │
│   │   다른 테이블/쿼리와 버퍼 캐시 경쟁                     │   │
│   │   → 벡터 데이터가 캐시에서 밀려날 수 있음               │   │
│   │                                                      │   │
│   └─────────────────────────────────────────────────────┘   │
│                                                              │
│   벡터 테이블 크기가 커지면 캐시 경쟁 심화                     │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

#### 문제 3: 네트워크 지연 변동성

```
로컬 환경:    [====] 일정함 (1-2ms)
AWS 환경:    [===========-----=====] 변동 있음 (1-10ms)
             ↑ 피크 시간대 지연 증가
```

### 5.4 AWS 환경 예상 성능

| 항목 | 로컬 (현재) | AWS (예상) | 증가율 |
|------|------------|-----------|--------|
| 임베딩 생성 | 350ms | 350-400ms | +0-15% |
| Spring 저장 | 10ms | 15-25ms | +50-150% |
| 벡터 검색 (Cold) | 40ms | 50-80ms | +25-100% |
| 벡터 검색 (Warm) | 20ms | 25-40ms | +25-100% |

### 5.5 AWS 환경 최적화 권장사항

#### 1. 같은 AZ(Availability Zone)에 배치
```
Spring Server (EC2/ECS) ─── 같은 AZ ─── RDS PostgreSQL
                                         │
                                    지연 최소화
```

#### 2. RDS 인스턴스 크기 선택
| 데이터 규모 | 권장 인스턴스 | 예상 비용 (월) |
|------------|-------------|--------------|
| 1,000개 이하 | db.t3.small | ~$30 |
| 10,000개 | db.t3.medium | ~$60 |
| 100,000개 이상 | db.r6g.large | ~$200 |

#### 3. Connection Pooling 필수
```java
// HikariCP 설정
spring:
  datasource:
    hikari:
      maximum-pool-size: 10
      minimum-idle: 5
      connection-timeout: 20000
      idle-timeout: 300000
```

---

## 6. 캐싱 전략 (Valkey 활용)

### 6.1 현재 상황 분석

```
┌─────────────────────────────────────────────────────────────────────────┐
│                        캐싱 가능/불가능 시나리오                           │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  ✅ 캐싱 가능한 경우:                                                    │
│     - 동일한 검색 쿼리 반복 (인기 검색어)                                  │
│     - 동일한 사용자의 반복 조회                                           │
│     - 추천 결과 목록 (TTL 기반 캐싱)                                      │
│                                                                         │
│  ❌ 캐싱 불가능한 경우 (Cold Start 발생):                                 │
│     - 새로운 사용자의 첫 번째 추천 요청                                    │
│     - 새로 등록된 프로젝트 검색                                           │
│     - 처음 보는 검색 쿼리                                                 │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### 6.2 첫 요청 문제 (Cache Miss 상황)

사용자가 **처음으로** 개발자/프로젝트 추천을 요청하는 경우:

```
사용자 A (첫 방문)
    │
    ▼
[Valkey 캐시 확인] → 캐시 없음 (Cache Miss)
    │
    ▼
[Spring 서버] → [pgvector 검색] → Cold Start 발생 가능
    │
    ▼
검색 시간: 40-80ms (AWS 기준)
    │
    ▼
[Valkey에 결과 저장] → TTL 설정 (예: 5분)
    │
    ▼
사용자에게 응답
```

### 6.3 캐싱 전략 권장사항

#### 전략 1: 예측 캐싱 (Predictive Caching)

인기 있는 검색/프로젝트 타입에 대해 미리 캐싱:

```python
# 스케줄러로 주기적 실행 (예: 1시간마다)
popular_tech_stacks = ["React", "Spring", "Node.js", "Python"]

for tech in popular_tech_stacks:
    embedding = generate_embedding(tech)
    results = search_similar(embedding)
    cache.set(f"recommend:{tech}", results, ttl=3600)
```

#### 전략 2: 계층적 캐싱

```
┌─────────────────────────────────────────────────────────────┐
│                     L1 Cache (Valkey)                        │
│                   TTL: 5분, 히트율: 70%                       │
│                   응답 시간: 1-2ms                            │
└─────────────────────────────┬────────────────────────────────┘
                              │ Cache Miss
                              ▼
┌─────────────────────────────────────────────────────────────┐
│              L2 Cache (PostgreSQL Buffer Cache)              │
│                   히트율: 90%, 응답 시간: 15-20ms             │
└─────────────────────────────┬────────────────────────────────┘
                              │ Cache Miss
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                    디스크 (최종 소스)                          │
│                   응답 시간: 30-50ms                          │
└─────────────────────────────────────────────────────────────┘
```

#### 전략 3: 결과 근사 캐싱

정확히 일치하는 쿼리가 없어도 유사한 캐시 결과 반환:

```python
# 벡터 유사도 기반 캐시 키 매칭
def get_cached_or_search(query_vector):
    # 1. 캐시된 쿼리들과 유사도 비교
    cached_keys = cache.get_keys("recommend:*")
    for key in cached_keys:
        cached_vector = cache.get(f"{key}:vector")
        similarity = cosine_similarity(query_vector, cached_vector)
        if similarity > 0.95:  # 95% 이상 유사하면 캐시 사용
            return cache.get(key)

    # 2. 캐시 미스: DB 검색
    results = db_search(query_vector)
    cache.set(f"recommend:{hash(query_vector)}", results)
    return results
```

### 6.4 캐싱 적용 시 예상 성능

| 시나리오 | 캐싱 없음 | Valkey 캐싱 적용 |
|---------|----------|-----------------|
| 첫 요청 (Cold) | 50-80ms | 50-80ms (동일) |
| 반복 요청 | 25-40ms | **1-2ms** |
| 유사 쿼리 | 25-40ms | **1-5ms** (근사 캐싱) |
| 전체 평균 | 35-50ms | **5-15ms** |

---

## 7. 종합 권장사항

### 7.1 즉시 적용 가능 (코드 변경만)

| 항목 | 현재 | 권장 | 예상 효과 |
|------|------|------|----------|
| 벡터 차원 | 1536 | 512 | 검색 2배 빠름, 저장 67% 감소 |
| 캐시 워밍업 | 없음 | 서버 시작 시 실행 | Cold Start 제거 |
| Valkey 캐싱 | 미적용 | TTL 5분 적용 | 반복 요청 95% 감소 |

### 7.2 인프라 변경 필요

| 항목 | 현재 | 권장 | 예상 효과 |
|------|------|------|----------|
| 인덱스 | IVFFlat | HNSW | 검색 2-5배 빠름 |
| shared_buffers | 128MB | 256MB+ | 캐시 히트율 향상 |
| RDS 인스턴스 | - | db.t3.medium+ | 안정적 성능 |

### 7.3 최종 예상 성능 (모든 최적화 적용 시)

| 환경 | 현재 | 최적화 후 |
|------|------|----------|
| 로컬 (Warm) | 15-20ms | **5-10ms** |
| AWS (Cold) | 50-80ms | **20-30ms** |
| AWS (Warm) | 25-40ms | **10-15ms** |
| AWS + Valkey 캐시 히트 | - | **1-2ms** |

---

## 8. 결론

### 8.1 테스트 결과 요약

1. **임베딩 생성**: OpenAI API 호출로 평균 350ms 소요 (네트워크 의존)
2. **벡터 저장**: Spring → PostgreSQL 약 10ms로 충분히 빠름
3. **벡터 검색**: 100개 기준 15-20ms, Cold Start 시 40ms까지 증가
4. **캐싱 효과**: 버퍼 캐시로 2배 성능 향상 확인

### 8.2 핵심 권장사항

1. **차원 축소 (1536 → 512)**: 가장 효과적인 최적화
2. **HNSW 인덱스**: 데이터 1만 개 이상 시 필수
3. **Valkey 캐싱**: 반복 요청 처리에 필수
4. **캐시 워밍업**: Cold Start 방지

### 8.3 다음 단계

1. 1,000개 / 10,000개 데이터로 추가 테스트
2. HNSW 인덱스 적용 후 성능 비교
3. 512차원 임베딩 정확도 검증
4. AWS 실제 환경 배포 및 성능 측정

---

*본 보고서는 로컬 개발 환경에서의 테스트 결과를 기반으로 작성되었습니다. 실제 프로덕션 환경에서는 추가적인 테스트와 튜닝이 필요합니다.*
